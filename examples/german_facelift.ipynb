{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import manifold, preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier as gpc\n",
    "import math\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix, csgraph\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "# sns.set(color_codes=False)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')\n",
    "\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Checking-account  Months  Credit-history  Purpose  Credit-amount   \n",
      "0                   1       6               4        3           1169  \\\n",
      "1                   2      48               2        3           5951   \n",
      "2                   4      12               4        6           2096   \n",
      "3                   1      42               2        2           7882   \n",
      "4                   1      24               3        0           4870   \n",
      "..                ...     ...             ...      ...            ...   \n",
      "995                 4      12               2        2           1736   \n",
      "996                 1      30               2        1           3857   \n",
      "997                 4      12               2        3            804   \n",
      "998                 1      45               2        3           1845   \n",
      "999                 2      45               4        1           4576   \n",
      "\n",
      "     Savings-account  Present-employment-since  Insatllment-rate   \n",
      "0                  5                         5                 4  \\\n",
      "1                  1                         3                 2   \n",
      "2                  1                         4                 2   \n",
      "3                  1                         4                 2   \n",
      "4                  1                         3                 3   \n",
      "..               ...                       ...               ...   \n",
      "995                1                         4                 3   \n",
      "996                1                         3                 4   \n",
      "997                1                         5                 4   \n",
      "998                1                         3                 4   \n",
      "999                2                         1                 3   \n",
      "\n",
      "     Personal-status  Other-debtors  ...  Property  age   \n",
      "0                  1              1  ...         1   67  \\\n",
      "1                  0              1  ...         1   22   \n",
      "2                  1              1  ...         1   49   \n",
      "3                  1              3  ...         2   45   \n",
      "4                  1              1  ...         4   53   \n",
      "..               ...            ...  ...       ...  ...   \n",
      "995                0              1  ...         1   31   \n",
      "996                1              1  ...         2   40   \n",
      "997                1              1  ...         3   38   \n",
      "998                1              1  ...         4   23   \n",
      "999                1              1  ...         3   27   \n",
      "\n",
      "     Other-installment-plans  Housing  Number-of-existing-credits  Job   \n",
      "0                          3        2                           2    3  \\\n",
      "1                          3        2                           1    3   \n",
      "2                          3        2                           1    2   \n",
      "3                          3        3                           1    3   \n",
      "4                          3        3                           2    3   \n",
      "..                       ...      ...                         ...  ...   \n",
      "995                        3        2                           1    2   \n",
      "996                        3        2                           1    4   \n",
      "997                        3        2                           1    3   \n",
      "998                        3        3                           1    3   \n",
      "999                        3        2                           1    3   \n",
      "\n",
      "     Number-of-people-being-lible  Telephone  Foreign-worker  target  \n",
      "0                               1          2               1       1  \n",
      "1                               1          1               1       0  \n",
      "2                               2          1               1       1  \n",
      "3                               2          1               1       1  \n",
      "4                               2          1               1       0  \n",
      "..                            ...        ...             ...     ...  \n",
      "995                             1          1               1       1  \n",
      "996                             1          2               1       1  \n",
      "997                             1          1               1       1  \n",
      "998                             1          2               1       0  \n",
      "999                             1          1               1       1  \n",
      "\n",
      "[1000 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# load german credit dataset\n",
    "# 1000 instances with 20 features\n",
    "data_path = \"../data/raw_data/german/german_redone.csv\"\n",
    "german_df = pd.read_csv(data_path)\n",
    "print(german_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path findings with FaceLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score: 0.74\n",
      "overall score 0.796\n",
      "number of negative instances in the test set: 50\n",
      "number of negative instances in the entire dataset: 242\n"
     ]
    }
   ],
   "source": [
    "X = german_df.iloc[:, :20]\n",
    "y = german_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X_train)\n",
    "X = scaler.transform(X)\n",
    "X_train_ = scaler.transform(X_train)\n",
    "X_test_ = scaler.transform(X_test)\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(4, 3), max_iter=10000, random_state=seed)\n",
    "clf.fit(X_train_, y_train)\n",
    "\n",
    "Y_test_pred = clf.predict(X_test_)\n",
    "Y_train_pred = clf.predict(X_train_)\n",
    "Y_all_pred = clf.predict_proba(X)\n",
    "print(\"test score:\", clf.score(X_test_, y_test))\n",
    "print(\"overall score\", clf.score(X, y))\n",
    "\n",
    "# number of negative instances in test set\n",
    "\n",
    "print(\"number of negative instances in the test set:\", (Y_test_pred == 0).sum())\n",
    "print(\"number of negative instances in the entire dataset:\", (Y_test_pred == 0).sum() + (Y_train_pred == 0).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_distance(v0, v1, penalty_term = 2):\n",
    "    # [x1, x2]\n",
    "    x_diff = v0[0] - v1[0]\n",
    "    y_diff_sign = v0[1] - v1[1]\n",
    "    y_diff = y_diff_sign if y_diff_sign >=0 else y_diff_sign*(-penalty_term)\n",
    "    diff_norm = np.linalg.norm([x_diff, y_diff])\n",
    "    return diff_norm\n",
    "\n",
    "def get_weights_kNN(\n",
    "    X, \n",
    "    n_neighbours = 20,\n",
    "    penalty_term = 2,\n",
    "    weight_func = None\n",
    "    ):\n",
    "    n_samples, n_ftrs = X.shape\n",
    "    \n",
    "    k = np.zeros((n_samples, n_samples))\n",
    "    W = copy.deepcopy(k)\n",
    "    # X = X.to_numpy()\n",
    "\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        v0 = X[i]\n",
    "        for j in range(n_samples):\n",
    "            v1 = X[j]\n",
    "            # modify the distance function so that removing pixels incurring larger cost.\n",
    "            # dist = calculate_weighted_distance(v1, v0, penalty_term=penalty_term)\n",
    "            dist = np.linalg.norm(v0 - v1)\n",
    "            k[i, j] = dist\n",
    "\n",
    "            if dist != 0:\n",
    "                # dist should be greater than r\n",
    "                W[i,j] = weight_func(dist)\n",
    "        \n",
    "        t = np.argsort(k[i, :])[(n_neighbours+1):]\n",
    "        mask = np.ix_(t)\n",
    "        k[i, mask] = 0\n",
    "        # W[i, mask] = 0\n",
    "\n",
    "    return k\n",
    "\n",
    "def get_weights_kde(\n",
    "    X, \n",
    "    n_neighbours = 20,\n",
    "    density_scorer = None,\n",
    "    weight_func = None\n",
    "    ):\n",
    "    n_samples, n_ftrs = X.shape\n",
    "    \n",
    "    k = np.zeros((n_samples, n_samples))\n",
    "    W = copy.deepcopy(k)\n",
    "    # X = X.to_numpy()\n",
    "\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        v0 = X[i]\n",
    "        for j in range(n_samples):\n",
    "            v1 = X[j]\n",
    "            dist = np.linalg.norm(v0 - v1)\n",
    "            k[i, j] = dist\n",
    "\n",
    "            if dist != 0:\n",
    "                # dist should be greater than r\n",
    "                mid_point = (v0 + v1)/2\n",
    "                mid_point_log_density = density_scorer(mid_point.reshape(1, -1))\n",
    "                if mid_point_log_density<0:\n",
    "                    W[i,j] = 0\n",
    "                else:\n",
    "                    W[i, j] = weight_func(mid_point_log_density)*dist\n",
    "        \n",
    "        t = np.argsort(k[i, :])[(n_neighbours+1):]\n",
    "        mask = np.ix_(t)\n",
    "        k[i, mask] = 0\n",
    "        W[i, mask] = 0\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(weight_matrix):\n",
    "    graph = csr_matrix(weight_matrix)\n",
    "    return graph\n",
    "\n",
    "def find_shortest_path(graph, start_point_idx):\n",
    "    dist_matrix, predecessors = csgraph.dijkstra(\n",
    "        csgraph=graph, directed=True, indices=start_point_idx, return_predecessors=True\n",
    "    )\n",
    "    return dist_matrix, predecessors\n",
    "\n",
    "def reconstruct_shortest_path(predecessors, start_point_idx, end_point_idx):\n",
    "    \"\"\"Get all the nodes along the path between the start point and the end point. \n",
    "\n",
    "    Args:\n",
    "        predecessors (matrix of shape (1, n_nodes)): contain the previous node in the path.\n",
    "        start_point_idx (int): the index of the start data point\n",
    "        end_point_idx (int): the index of the end data point\n",
    "\n",
    "    Returns:\n",
    "        node_path (list): [start_point_idx, intermedium points index, end_point_idx]\n",
    "    \"\"\"\n",
    "    if predecessors[end_point_idx] == start_point_idx:\n",
    "        node_path = [end_point_idx]\n",
    "    else:\n",
    "        node_path = []\n",
    "    intermedium_idx = end_point_idx\n",
    "    while (predecessors[intermedium_idx] != start_point_idx):\n",
    "        node_path.append(intermedium_idx)\n",
    "        intermedium_idx = predecessors[intermedium_idx]\n",
    "    if intermedium_idx != node_path[-1]:\n",
    "        node_path.append(intermedium_idx)\n",
    "    node_path.append(start_point_idx)\n",
    "    \n",
    "    return node_path[::-1]\n",
    " \n",
    "def build_symmetric_matrix(kernel):\n",
    "    for i in range(kernel.shape[0]):\n",
    "        for j in range(i):\n",
    "            if kernel[j, i] != 0:\n",
    "                kernel[i, j] = kernel[j, i]\n",
    "            else:\n",
    "                kernel[j, i] = kernel[i, j]\n",
    "    return kernel\n",
    "\n",
    "def build_asymmetric_matrix(kernel, X, weight_func, penalty_term):\n",
    "    n_samples = kernel.shape[0]\n",
    "    X = X.to_numpy()\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        for j in range(n_samples):\n",
    "            if kernel[i,j] != 0:\n",
    "                v0 = X[i]\n",
    "                v1 = X[j]\n",
    "                dist = calculate_weighted_distance(v0, v1, penalty_term=penalty_term)\n",
    "                kernel[j, i] = dist\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_estimator = KernelDensity(kernel=\"gaussian\", metric=\"l2\", bandwidth=0.077)\n",
    "kd_estimator.fit(X)\n",
    "density_scorer = kd_estimator.score_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 150.00it/s]\n"
     ]
    }
   ],
   "source": [
    "n_neighbours = 3\n",
    "penalty_term = 100\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "def get_volume_of_sphere(d):\n",
    "    return math.pi**(d/2)/math.gamma(d/2 + 1)\n",
    "\n",
    "volume_sphere = get_volume_of_sphere(n_features)\n",
    "r = (n_neighbours / (n_samples * volume_sphere))\n",
    "# print(r)    # 0.010\n",
    "\n",
    "# Construct the global weighted graph.\n",
    "# Kernel is asymmetric if using KNN to get weight, and OG only keeps the bottom left half of the matrix\n",
    "\n",
    "weight_func=lambda x: -x*np.log(r/x)  # x**alpha\n",
    "kernel = get_weights_kNN(\n",
    "            X,\n",
    "            penalty_term=penalty_term,\n",
    "            n_neighbours=int(n_neighbours),\n",
    "            weight_func=weight_func\n",
    "        )\n",
    "\n",
    "# kernel = get_weights_kde(X, \n",
    "#                          n_neighbours=n_neighbours,\n",
    "#                          weight_func=lambda x: 10/x,\n",
    "#                          density_scorer=density_scorer\n",
    "# )\n",
    "sym_kernel = build_symmetric_matrix(kernel)\n",
    "# asym_kernel = build_asymmetric_matrix(kernel, X, weight_func, penalty_term)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[-0.06064321]\n",
      "[-33.51292353]\n",
      "2.0323311185410073\n"
     ]
    }
   ],
   "source": [
    "print(kernel[0][76])\n",
    "# X_array = X.to_numpy()\n",
    "x1 = X[0]\n",
    "x78 = X[76]\n",
    "dist = np.linalg.norm(x1 - x78)\n",
    "log_den = density_scorer(((x1+x78)/2).reshape(1, -1))\n",
    "print((1/log_den)*dist)\n",
    "print(log_den)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_dist(dist_matrix):\n",
    "    \"\"\"get the shortest distance and its data index\n",
    "    Args:\n",
    "        dist_matrix (array): shape: 1 x n_nodes\n",
    "\n",
    "    Returns:\n",
    "        min_dist: minimum distance in the distance matrix\n",
    "        min_dist_idx: index of the data point with the shortest dist\n",
    "    \"\"\"\n",
    "    min_dist = np.min(np.ma.masked_where(dist_matrix==0, dist_matrix, copy=False)) \n",
    "    min_dist_idx = np.argmin(np.ma.masked_where(dist_matrix==0, dist_matrix, copy=False))\n",
    "    return min_dist, min_dist_idx\n",
    "\n",
    "def get_closest_cf_point(dist_matrix, predictions, y, target_class, class_labels, num_paths = 1, pred_threshold=0.9):\n",
    "    assert num_paths > 0 and isinstance(num_paths, int), \"only positive integers\"\n",
    "    end_point_idx = []\n",
    "    path_count = 0\n",
    "    for idx in np.argsort(np.ma.masked_where(dist_matrix==0, dist_matrix)):\n",
    "        if (y[idx] == target_class and\n",
    "        predictions[idx, class_labels.index(target_class)] >= pred_threshold): \n",
    "            end_point_idx.append(idx)\n",
    "            if path_count >= num_paths-1:\n",
    "                break\n",
    "            else:\n",
    "                path_count += 1\n",
    "    return end_point_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [5, 829, 886], 1: [5, 685, 791], 2: [5, 685, 406], 3: [5, 685, 406, 787], 4: [5, 685, 406, 933], 5: [5, 685, 406, 716], 6: [5, 685, 406, 939], 7: [5, 829, 886, 830], 8: [5, 685, 791, 940], 9: [5, 685, 406, 65], 10: [5, 87, 684, 42], 11: [5, 685, 791, 327], 12: [5, 685, 406, 933, 160], 13: [5, 685, 406, 716, 19], 14: [5, 87, 796, 277], 15: [5, 685, 406, 933, 499], 16: [5, 685, 406, 933, 223], 17: [5, 829, 946, 737, 529], 18: [5, 829, 946, 737, 923], 19: [5, 829, 886, 830, 178], 20: [5, 829, 886, 830, 473], 21: [5, 829, 886, 830, 863], 22: [5, 685, 406, 933, 160, 415], 23: [5, 685, 406, 716, 19, 854], 24: [5, 685, 406, 933, 499, 738], 25: [5, 87, 796, 277, 94], 26: [5, 87, 796, 277, 0], 27: [5, 87, 796, 277, 845, 254], 28: [5, 87, 796, 277, 94, 712], 29: [5, 87, 796, 277, 94, 781], 30: [5, 87, 796, 277, 94, 61], 31: [5, 87, 796, 277, 845, 299, 686], 32: [5, 87, 796, 277, 845, 299, 119], 33: [5, 87, 796, 277, 845, 299, 506], 34: [5, 87, 796, 277, 94, 781, 183], 35: [5, 87, 796, 277, 94, 712, 742], 36: [5, 87, 796, 277, 94, 781, 484], 37: [5, 829, 946, 737, 479, 205, 292], 38: [5, 87, 796, 277, 94, 712, 928], 39: [5, 87, 796, 277, 845, 299, 718, 894], 40: [5, 829, 946, 737, 479, 184, 150], 41: [5, 87, 796, 277, 94, 712, 742, 994], 42: [5, 87, 796, 277, 94, 781, 183, 628], 43: [5, 87, 796, 277, 94, 712, 742, 162], 44: [5, 87, 796, 277, 845, 299, 686, 71], 45: [5, 87, 796, 277, 94, 781, 183, 851], 46: [5, 87, 796, 277, 845, 299, 718, 549], 47: [5, 87, 796, 277, 94, 712, 928, 798], 48: [5, 87, 796, 277, 94, 712, 742, 81], 49: [5, 87, 796, 277, 845, 254, 41, 785]}\n"
     ]
    }
   ],
   "source": [
    "# calculate the shared percentage\n",
    "# make sure the alternative points are epsilon distance away from each other\n",
    "\n",
    "# print(cf_solutions[start_point_idx])\n",
    "\n",
    "def calculate_shared_stop_point(sp_graph, path, alter_cf):\n",
    "    stop_point = path[0]\n",
    "    for idx, node in enumerate(path):\n",
    "        # if not the last node\n",
    "        if idx < len(path)-1:\n",
    "            dist_matrix, _ = find_shortest_path(sp_graph, start_point_idx=node)\n",
    "            dist_matrix_next, _ = find_shortest_path(sp_graph, start_point_idx=path[idx+1])\n",
    "            if dist_matrix[alter_cf] < dist_matrix_next[alter_cf]:\n",
    "                stop_point = node\n",
    "                break\n",
    "        # if the last node\n",
    "        else:\n",
    "            stop_point = node\n",
    "    return stop_point\n",
    "\n",
    "def calculate_shared_perc(sp_graph, path, stop_point):\n",
    "    dist_matrix, _ = find_shortest_path(sp_graph, start_point_idx=path[0])\n",
    "    perc = dist_matrix[stop_point]/dist_matrix[path[-1]]\n",
    "    return perc\n",
    "\n",
    "def dissimilarity(list1, list2):\n",
    "    counter1 = Counter(list1)\n",
    "    counter2 = Counter(list2)\n",
    "    common_count = sum((counter1 & counter2).values())\n",
    "    total_count = len(list1) + len(list2)\n",
    "    return total_count - 2 * common_count\n",
    "\n",
    "def find_alternative_cfs(all_path_dict, base_id = 0, count=5):\n",
    "    # find top-count paths that are dissimilar to the base_id path\n",
    "    dissimilarities = {key: dissimilarity(all_path_dict[base_id], value) for key, value in all_path_dict.items() if key != base_id}\n",
    "    top_dissimilar_lists = sorted(dissimilarities, key=dissimilarities.get, reverse=True)[:count]\n",
    "    return top_dissimilar_lists\n",
    "\n",
    "stop_point = calculate_shared_stop_point(sp_graph, [4, 501, 611, 705], 393)\n",
    "shared_perc = calculate_shared_perc(sp_graph, [1, 691, 834, 995], stop_point)\n",
    "# print(stop_point)\n",
    "\n",
    "def calculate_opportunity_potential(solution_dict, path_id):\n",
    "    alter_cfs = find_alternative_cfs(solution_dict, base_id=path_id)\n",
    "    # print(alter_cfs)\n",
    "\n",
    "    avg_shared_perc = []\n",
    "    for alter_path in alter_cfs:\n",
    "        alter_end_node = solution_dict[alter_path][-1]\n",
    "        first_path = solution_dict[0]\n",
    "        # print(alter_end_node)\n",
    "        stop_point = calculate_shared_stop_point(sp_graph, first_path, alter_end_node)\n",
    "        shared_perc = calculate_shared_perc(sp_graph, first_path, stop_point)\n",
    "        avg_shared_perc.append(shared_perc)\n",
    "    # print(np.mean(avg_shared_perc))\n",
    "    return(np.mean(avg_shared_perc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[886, 791, 406, 787, 933, 716, 939, 830, 940, 65, 42, 327, 160, 19, 277, 499, 223, 529, 923, 178, 473, 863, 415, 854, 738, 94, 0, 254, 712, 781, 61, 686, 119, 506, 183, 742, 484, 292, 928, 894, 150, 994, 628, 162, 71, 851, 549, 798, 81, 785]\n",
      "{5: {0: [5, 829, 886], 1: [5, 685, 791], 2: [5, 685, 406], 3: [5, 685, 406, 787], 4: [5, 685, 406, 933], 5: [5, 685, 406, 716], 6: [5, 685, 406, 939], 7: [5, 829, 886, 830], 8: [5, 685, 791, 940], 9: [5, 685, 406, 65], 10: [5, 87, 684, 42], 11: [5, 685, 791, 327], 12: [5, 685, 406, 933, 160], 13: [5, 685, 406, 716, 19], 14: [5, 87, 796, 277], 15: [5, 685, 406, 933, 499], 16: [5, 685, 406, 933, 223], 17: [5, 829, 946, 737, 529], 18: [5, 829, 946, 737, 923], 19: [5, 829, 886, 830, 178], 20: [5, 829, 886, 830, 473], 21: [5, 829, 886, 830, 863], 22: [5, 685, 406, 933, 160, 415], 23: [5, 685, 406, 716, 19, 854], 24: [5, 685, 406, 933, 499, 738], 25: [5, 87, 796, 277, 94], 26: [5, 87, 796, 277, 0], 27: [5, 87, 796, 277, 845, 254], 28: [5, 87, 796, 277, 94, 712], 29: [5, 87, 796, 277, 94, 781], 30: [5, 87, 796, 277, 94, 61], 31: [5, 87, 796, 277, 845, 299, 686], 32: [5, 87, 796, 277, 845, 299, 119], 33: [5, 87, 796, 277, 845, 299, 506], 34: [5, 87, 796, 277, 94, 781, 183], 35: [5, 87, 796, 277, 94, 712, 742], 36: [5, 87, 796, 277, 94, 781, 484], 37: [5, 829, 946, 737, 479, 205, 292], 38: [5, 87, 796, 277, 94, 712, 928], 39: [5, 87, 796, 277, 845, 299, 718, 894], 40: [5, 829, 946, 737, 479, 184, 150], 41: [5, 87, 796, 277, 94, 712, 742, 994], 42: [5, 87, 796, 277, 94, 781, 183, 628], 43: [5, 87, 796, 277, 94, 712, 742, 162], 44: [5, 87, 796, 277, 845, 299, 686, 71], 45: [5, 87, 796, 277, 94, 781, 183, 851], 46: [5, 87, 796, 277, 845, 299, 718, 549], 47: [5, 87, 796, 277, 94, 712, 928, 798], 48: [5, 87, 796, 277, 94, 712, 742, 81], 49: [5, 87, 796, 277, 845, 254, 41, 785]}}\n"
     ]
    }
   ],
   "source": [
    "sp_graph = construct_graph(sym_kernel)\n",
    "\n",
    "start_point_idx = 5\n",
    "target_class = 1\n",
    "pred_threshold = 0.9\n",
    "class_labels = list(map(int, clf.classes_))\n",
    "cf_solutions = {}\n",
    "cf_solutions[start_point_idx] = {}\n",
    "\n",
    "dist_matrix, predecessors = find_shortest_path(sp_graph, start_point_idx=start_point_idx)\n",
    "\n",
    "end_point_indices = get_closest_cf_point(dist_matrix, Y_all_pred, y, target_class, class_labels, num_paths=50, pred_threshold=pred_threshold)\n",
    "print(end_point_indices)\n",
    "\n",
    "for order, end_point_idx in enumerate(end_point_indices):\n",
    "    shortest_path = reconstruct_shortest_path(predecessors, start_point_idx=start_point_idx, end_point_idx=end_point_idx)\n",
    "    for node_idx in shortest_path[:-1]:\n",
    "        cf_solutions[start_point_idx][order] = shortest_path\n",
    "print(cf_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 10, 11, 13, 14, 15, 18, 25, 29, 30, 31, 35, 44, 54, 56, 59, 62, 63, 75, 76, 79, 89, 95, 101, 113, 116, 120, 125, 126, 131, 138, 141, 142, 143, 148, 158, 163, 166, 170, 174, 175, 176, 181, 182, 189, 191, 197, 201, 203, 212, 218, 221, 226, 227, 235, 242, 252, 257, 261, 265, 272, 273, 274, 285, 286, 287, 289, 295, 301, 307, 315, 320, 321, 323, 332, 333, 334, 337, 338, 341, 353, 355, 359, 364, 368, 375, 378, 381, 387, 392, 396, 405, 412, 414, 416, 429, 431, 438, 442, 446, 457, 458, 462, 465, 466, 471, 472, 475, 481, 491, 496, 500, 501, 503, 504, 521, 522, 525, 528, 530, 538, 540, 545, 548, 552, 556, 557, 558, 560, 561, 566, 568, 569, 573, 578, 580, 583, 585, 588, 596, 597, 600, 602, 605, 607, 610, 612, 613, 623, 624, 630, 631, 637, 639, 640, 646, 648, 649, 650, 656, 663, 666, 677, 678, 701, 707, 711, 714, 719, 720, 721, 722, 727, 728, 730, 736, 739, 740, 743, 747, 751, 755, 762, 766, 771, 783, 789, 805, 808, 809, 812, 813, 814, 818, 819, 822, 826, 827, 831, 832, 835, 840, 849, 850, 853, 866, 869, 876, 878, 885, 887, 911, 914, 915, 917, 918, 919, 922, 924, 925, 927, 929, 931, 935, 938, 944, 945, 946, 953, 958, 972, 973, 981, 982, 983, 985, 988, 991, 993, 998]\n",
      "0.4066306844673344\n",
      "0.3132756973044767\n",
      "2.1621725370138365\n",
      "0.7246901054489474\n"
     ]
    }
   ],
   "source": [
    "# find all negative instances\n",
    "y_pred_bin = clf.predict(X)\n",
    "all_neg_indices = [index for index, value in enumerate(y_pred_bin) if value == 0]\n",
    "print(all_neg_indices)\n",
    "\n",
    "# for a single instance, find one that is \n",
    "def find_solutions(sp_graph, start_point_idx, num_paths):\n",
    "    target_class = 1\n",
    "    pred_threshold = 0.9\n",
    "    class_labels = list(map(int, clf.classes_))\n",
    "    cf_solutions = {}\n",
    "    cf_solutions[start_point_idx] = {}\n",
    "\n",
    "    dist_matrix, predecessors = find_shortest_path(sp_graph, start_point_idx=start_point_idx)\n",
    "\n",
    "    end_point_indices = get_closest_cf_point(dist_matrix, Y_all_pred, y, target_class, class_labels, num_paths=num_paths, pred_threshold=pred_threshold)\n",
    "    # print(end_point_indices)\n",
    "    \n",
    "    for order, end_point_idx in enumerate(end_point_indices):\n",
    "        shortest_path = reconstruct_shortest_path(predecessors, start_point_idx=start_point_idx, end_point_idx=end_point_idx)\n",
    "        for node_idx in shortest_path[:-1]:\n",
    "            cf_solutions[start_point_idx][order] = shortest_path\n",
    "    # print(cf_solutions)\n",
    "    return cf_solutions[start_point_idx], dist_matrix\n",
    "\n",
    "avg_oppo_pot = []\n",
    "avg_dist = []\n",
    "for instance_idx in all_neg_indices:\n",
    "    solution, dist_matrix = find_solutions(sp_graph, instance_idx, num_paths=30)\n",
    "    # solution_dict = cf_solutions[start_point_idx]\n",
    "    oppo_pot = calculate_opportunity_potential(solution, path_id=0)\n",
    "    avg_oppo_pot.append(oppo_pot)\n",
    "    avg_dist.append(dist_matrix[solution[0][-1]])\n",
    "print(np.mean(avg_oppo_pot))\n",
    "print(np.std(avg_oppo_pot))\n",
    "print(np.mean(avg_dist))\n",
    "print(np.std(avg_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6517980489426524\n",
      "0.306225505908013\n",
      "2.5398832673036282\n",
      "0.9854628105825265\n"
     ]
    }
   ],
   "source": [
    "avg_oppo_pot = []\n",
    "avg_dist = []\n",
    "for instance_idx in all_neg_indices:\n",
    "    solution, dist_matrix = find_solutions(sp_graph, instance_idx, num_paths=30)\n",
    "    max_oppo = 0\n",
    "    max_oppo_dist = 0\n",
    "    for i in range(10):\n",
    "        oppo_pot = calculate_opportunity_potential(solution, path_id=i)\n",
    "        if oppo_pot>max_oppo:\n",
    "            max_oppo = oppo_pot\n",
    "            max_oppo_dist = dist_matrix[solution[i][-1]]\n",
    "    avg_oppo_pot.append(max_oppo)\n",
    "    avg_dist.append(max_oppo_dist)\n",
    "\n",
    "print(np.mean(avg_oppo_pot))\n",
    "print(np.std(avg_oppo_pot))\n",
    "print(np.mean(avg_dist))\n",
    "print(np.std(avg_dist))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facelift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
