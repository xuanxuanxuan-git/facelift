{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With image data, only few methods work -- FACE, GS, prototype\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neural_network import MLPClassifier as NN\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find the closest instance (using growing sphere) or any final solution\n",
    "# Step 2: compute the pixel difference r\n",
    "# Step 3: binary space partition, and then sort the indices by their distances to the cf instance\n",
    "\n",
    "def calculate_dist(instance_1, instance_2, norm=2):\n",
    "    dist = np.linalg.norm((instance_1 - instance_2), ord=norm)\n",
    "    return dist\n",
    "\n",
    "def find_closest_cf_instance(factual_point_idx, dataset, predictions, cf_class):\n",
    "    min_dist = 785\n",
    "    closest_id = None\n",
    "    factual_point = np.array(dataset.loc[factual_point_idx])\n",
    "    for it_count, (idx, instance) in enumerate(dataset.iterrows()):\n",
    "        prediction = np.argmax(predictions[it_count])\n",
    "        prediction_prob = np.max(predictions[it_count])\n",
    "        if prediction == cf_class and prediction_prob>0.8:\n",
    "            dist = calculate_dist(factual_point, np.array(instance))\n",
    "            # print(idx, dist)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_id = idx\n",
    "    \n",
    "    assert closest_id != None, (\"No counterfactual found\")\n",
    "    return closest_id, min_dist\n",
    "\n",
    "def find_closest_instance(anchor_point, dataset):\n",
    "    min_dist = 785\n",
    "    closest_id = None\n",
    "    for idx, instance in dataset.iterrows():\n",
    "        dist = calculate_dist(anchor_point, instance)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest_id = idx\n",
    "        \n",
    "    assert closest_id != None, (\"No factual point found, try increasing epsilon.\")\n",
    "    return closest_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_point(data, start_point_idx, cf_point_idx, epsilon):\n",
    "    start_point = np.array(data.loc[start_point_idx])\n",
    "    cf_point = np.array(data.loc[cf_point_idx])\n",
    "\n",
    "    distances = pairwise_distances(data.values, [start_point, cf_point], metric=\"l2\")\n",
    "    \n",
    "    ball_indices = np.where((distances[:,0] <= epsilon) & (distances[:, 1] <= epsilon))[0]\n",
    "    ball_indices = list(ball_indices)\n",
    "    if start_point_idx in ball_indices:\n",
    "        ball_indices.remove(start_point_idx)\n",
    "    if cf_point_idx in ball_indices:\n",
    "        ball_indices.remove(cf_point_idx)\n",
    "    return ball_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 10000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "image_size = 28\n",
    "no_of_different_labels = 10\n",
    "image_pixels = image_size * image_size\n",
    "data_path = \"../data/raw_data/mnist/mnist_train.csv\"\n",
    "\n",
    "train_data = pd.read_csv(data_path, \n",
    "                        delimiter=\",\", header=None, dtype=np.uint8)\n",
    "train_imgs = train_data.iloc[:, 1:]/255   # divide by 255 only for model prediction\n",
    "train_imgs = train_imgs.astype(\"float32\")\n",
    "# train_imgs = train_data.iloc[:, 1:]\n",
    "train_labels = np.asarray(train_data.iloc[:, :1][0])\n",
    "\n",
    "# subsample the original dataset, each digit has 1000 instances rather than 5000-6000\n",
    "all_indices = []\n",
    "for digit in np.arange(0,10):\n",
    "    single_digit_indices = set(np.where(train_labels == digit)[0][:1000])\n",
    "    all_indices = set(all_indices).union(single_digit_indices)\n",
    "print(\"Number of instances:\", len(all_indices))\n",
    "\n",
    "X = train_imgs.iloc[list(all_indices), :]\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "y = train_labels[list(all_indices)]\n",
    "\n",
    "clf = NN(max_iter=5000).fit(X, y)\n",
    "predictions = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of counterfactual instance: 3510\n",
      "Distance: 6.379251\n",
      "[23, 77, 78, 113, 177, 201, 205, 315, 345, 351, 355, 357, 397, 443, 447, 455, 475, 492, 507, 508, 553, 573, 593, 609, 611, 671, 691, 698, 711, 747, 765, 779, 783, 809, 833, 835, 871, 891, 905, 919, 959, 1051, 1085, 1115, 1181, 1211, 1331, 1405, 1425, 1445, 1497, 1527, 1579, 1597, 1601, 1909, 1915, 2039, 2045, 2047, 2166, 2335, 2355, 2393, 2429, 2495, 2497, 2505, 2563, 2583, 2645, 2667, 2695, 2717, 2719, 2807, 2823, 2831, 2843, 2853, 2907, 3331, 3373, 3411, 3427, 3487, 3549, 3561, 3567, 3605, 3729, 3733, 3797, 3831, 3851, 3885, 3889, 3897, 3955, 3956, 4029, 4069, 4105, 4109, 4129, 4137, 4149, 4193, 4225, 4237, 4267, 4351, 4405, 4445, 4553, 4561, 4569, 4623, 4685, 4933, 5051, 5073, 5075, 5107, 5149, 5189, 5221, 5225, 5235, 5237, 5245, 5271, 5301, 5375, 5395, 5425, 5428, 5429, 5439, 5443, 5477, 5483, 5527, 5543, 5571, 5601, 5635, 5643, 5655, 5667, 5675, 5681, 5713, 5731, 5749, 5785, 5859, 5903, 5915, 5933, 5957, 6075, 6083, 6135, 6165, 6183, 6229, 6247, 6303, 6356, 6365, 6371, 6411, 6413, 6423, 6499, 6531, 6613, 6877, 6925, 6985, 7007, 7057, 7119, 7188, 7421, 7435, 7454, 7533, 7729, 7837, 7857, 7951, 7971, 7993, 8053, 8063, 8083, 8087, 8095, 8112, 8203, 8255, 8258, 8291, 8319, 8331, 8373, 8379, 8383, 8388, 8423, 8512, 8589, 8625, 8679, 8705, 8725]\n"
     ]
    }
   ],
   "source": [
    "factual_img_idx = 3 # digit 1\n",
    "cf_class = 9\n",
    "\n",
    "cf_img_idx, cf_img_dis = find_closest_cf_instance(factual_img_idx, X, predictions, cf_class)\n",
    "print(\"Index of counterfactual instance:\", cf_img_idx)\n",
    "print(\"Distance:\", cf_img_dis)\n",
    "\n",
    "all_path_points = find_point(X, factual_img_idx, cf_img_idx, cf_img_dis)\n",
    "print(all_path_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3510\n",
      "[3, 8725, 4149, 5749, 691, 3510]\n"
     ]
    }
   ],
   "source": [
    "# BSP Algorithm\n",
    "def bsp_partition(data, indices, point1, point2, threshold):\n",
    "    distances = pairwise_distances(data[indices], [point1, point2], metric='l2')\n",
    "    partition = np.where((distances[:,0] <= threshold) & (distances[:, 1] <= threshold))[0]\n",
    "    return indices[partition]\n",
    "\n",
    "# Recursive BSP function\n",
    "def recursive_bsp(data, indices, point1, point2, threshold, min_threshold):\n",
    "\n",
    "    if threshold < min_threshold:\n",
    "        np.random.seed(42)\n",
    "        result = np.random.choice(indices, size=1)\n",
    "        return result\n",
    "    \n",
    "    midpoint = (point1 + point2) / 2.0\n",
    "    threshold = threshold-1\n",
    "    partition1 = bsp_partition(data, indices, point1, midpoint, threshold)\n",
    "    partition2 = bsp_partition(data, indices, midpoint, point2, threshold)\n",
    "    \n",
    "    if len(partition1) + len(partition2) == 0:\n",
    "        np.random.seed(42)\n",
    "        result = np.random.choice(indices, size=1)\n",
    "        return result\n",
    "    else:\n",
    "        if len(partition1) != 0:\n",
    "            indices1 = recursive_bsp(data, partition1, point1, midpoint, threshold, min_threshold)\n",
    "        else:   # in this case, partition2 is not empty\n",
    "            indices1 = []\n",
    "        \n",
    "        if len(partition2) != 0:\n",
    "            indices2 = recursive_bsp(data, partition2, midpoint, point2, threshold, min_threshold)\n",
    "        else:\n",
    "            indices2 = []\n",
    "\n",
    "    return np.concatenate((indices1, indices2))\n",
    "\n",
    "def sort_path_points(X_np, selected_indices, cf_img):\n",
    "    cf_point = np.array(cf_img).reshape(1, -1)\n",
    "\n",
    "    distances = pairwise_distances(X_np[selected_indices], cf_point, metric=\"l2\")\n",
    "    distances = np.squeeze(distances)\n",
    "    sorted_indices = np.array(selected_indices)[np.argsort(distances)][::-1]\n",
    "\n",
    "    return list(sorted_indices)\n",
    "\n",
    "def ground_vector_path(X_np, factual_img_idx, cf_img_idx, cf_img_dis, all_indices, min_threshold):\n",
    "    if not all_indices:\n",
    "        return []\n",
    "    \n",
    "    point1 = X_np[factual_img_idx]\n",
    "    point2 = X_np[cf_img_idx]\n",
    "    initial_threshold = cf_img_dis\n",
    "\n",
    "    min_threshold = min_threshold\n",
    "    all_indices = np.array(all_indices)\n",
    "\n",
    "    selected_indices = recursive_bsp(X_np, all_indices, point1, point2, initial_threshold, min_threshold)\n",
    "    selected_indices = list(map(int, set(selected_indices)))\n",
    "    # print(selected_indices)\n",
    "    sorted_indices = sort_path_points(X_np, selected_indices, point2)\n",
    "    sorted_indices.append(cf_img_idx)\n",
    "    sorted_indices.insert(0, factual_img_idx)\n",
    "    return sorted_indices\n",
    "\n",
    "\n",
    "print(factual_img_idx)\n",
    "print(cf_img_idx)\n",
    "X_np = X.to_numpy()\n",
    "selected_path_points = ground_vector_path(X_np, factual_img_idx, cf_img_idx, cf_img_dis, all_indices=all_path_points, min_threshold=2)\n",
    "print(selected_path_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:48<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 8725, 4149, 5749, 691, 3510], [6, 8660, 6052, 5256, 8382, 7922], [8, 2616, 3900, 7588, 3662], [14, 7650, 8032, 3662], [23, 201, 4105, 611, 7233], [24, 5174, 9717], [40, 7060, 3714, 3662], [59, 3729, 2583, 1579, 691, 3510], [67, 7472, 4708, 2198, 7176, 5390], [70, 7898, 8732, 48], [72, 1942, 3662], [77, 5601, 5395, 3956, 691, 3510], [78, 7533, 7119, 691, 3510], [99, 1081, 1463, 7365], [102, 7020, 6748, 7138, 7588, 3662], [104, 3272, 5336, 8382, 7922], [105, 6613, 1181, 6499, 3956, 3510], [112, 3926, 5530, 3662], [113, 3956, 3510], [124, 7603, 7176, 5390], [128, 3478, 3394, 5708, 7393, 8574, 3662], [134, 3070, 9508], [152, 6775, 4166, 4070, 8602, 3714, 3662], [174, 2906, 8106, 3662], [177, 6247, 1445, 5691, 3355], [184, 5814, 6586, 7588, 3662], [200, 4467, 6116, 746, 2600], [201, 5749, 691, 3510], [205, 779, 8679, 3956, 3510], [208, 6208, 4913, 251, 3703, 3355], [211, 6208, 4913, 5691, 3355], [224, 9214, 8217, 6459], [231, 2894, 2154, 4166, 8602, 5390], [248, 1696, 5256, 6702, 7922], [251, 6395, 5691, 3355], [269, 4953, 4286, 3345, 3755, 7973, 5114, 5691, 3355], [270, 6384, 4998, 6793, 8602, 5390], [276, 8106, 2198, 3662], [290, 1658, 2870, 3878, 7469, 5390], [309, 3971, 2957, 3295, 7472, 5428, 1521, 7365], [310, 3714, 8032, 3662], [315, 7533, 5571, 8589, 691, 3510], [345, 315, 5075, 5571, 691, 3510], [351, 8589, 3510], [355, 5075, 8083, 3956, 691, 3510], [357, 7971, 3510], [358, 7572, 6926, 2616, 4790, 7650, 7588, 3662], [366, 72, 4484, 3662], [382, 1450, 4731, 6116, 4813, 7074, 2600], [394, 8040, 7850, 5020, 8176, 5898], [397, 5543, 891, 3956, 3510], [398, 5058, 484, 4484, 3662], [406, 248, 6052, 5256, 4942, 7922], [408, 4186, 4772, 8106, 8032, 3662], [416, 6247, 6395, 3355], [443, 5675, 891, 5731, 691, 3510], [447, 871, 397, 5107, 3956, 3510], [450, 6408, 7324, 4772, 7060, 3714, 4484, 3662], [454, 4064, 3120, 4484, 3662], [455, 5601, 5643, 691, 3510], [466, 7912, 6122, 5390], [470, 2830, 5898], [475, 3549, 7233], [484, 5882, 6244, 4484, 3662], [491, 7747, 3545, 3798, 7233], [492, 6371, 5527, 691, 3510], [507, 5749, 1497, 3510], [508, 4105, 5189, 3549, 8185, 7233], [510, 2692, 1807, 3763, 7609, 6380, 5898], [533, 491, 5305, 3545, 8185, 7233], [535, 7747, 8351, 3798, 7233], [538, 1065, 7609, 7491, 7317, 1031, 7365], [552, 4476, 6647, 2906, 8574, 3662], [553, 1085, 3733, 691, 3510], [556, 8156, 8166, 3412, 3662], [572, 8538, 5610, 7060, 3714, 3662], [573, 5749, 3510], [587, 7747, 3509, 8185, 7233], [593, 8291, 7303, 475, 8185, 7233], [604, 8402, 3662], [609, 4149, 5749, 691, 3510], [618, 3306, 5058, 3900, 3662], [637, 7831, 1155, 2811, 3103, 6736, 7303, 8185, 611, 7233], [638, 5864, 2716, 3900, 3120, 3662], [648, 8738, 5114, 4166, 8402, 7176, 5390], [671, 691, 3510], [676, 7324, 7469, 3926, 276, 3662], [678, 4492, 7060, 7588, 3662], [], [698, 2393, 6499, 8053, 3956, 3510], [710, 8348, 4766, 7838, 2906, 3662], [711, 6423, 1915, 691, 3510], [738, 5336, 4696, 7922], [747, 5221, 5149, 905, 691, 3510], [765, 8083, 8053, 3956, 691, 3510], [779, 891, 1915, 8679, 691, 3510], [780, 7572, 2616, 7588, 3662], [783, 205, 891, 3956, 1497, 3510], [809, 833, 8373, 5395, 3956, 3510], [821, 6463, 8331, 7421, 8087, 959, 3510]]\n",
      "average path length: 5.21, std: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_points_list = []\n",
    "X_np = X.to_numpy()\n",
    "top_100_one_indices = list(np.where(y==1)[0])[:100]\n",
    "\n",
    "for idx in tqdm(top_100_one_indices):\n",
    "    \n",
    "    factual_img_idx = idx\n",
    "    cf_img_idx, cf_img_dis = find_closest_cf_instance(factual_img_idx, X, predictions, cf_class)\n",
    "    # print(factual_img_idx, cf_img_idx)\n",
    "    all_path_points = find_point(X, factual_img_idx, cf_img_idx, cf_img_dis)\n",
    "    selected_path_points = ground_vector_path(X_np, factual_img_idx, cf_img_idx, cf_img_dis, all_path_points, min_threshold=2)\n",
    "    path_points_list.append(selected_path_points)\n",
    "print(path_points_list)\n",
    "path_len = [len(path) for path in path_points_list]\n",
    "print(\"average path length: {}, std: {}\".format(round(np.average(path_len), 2), round(np.std(path_len), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [17:26<14:32, 21.28s/it]"
     ]
    }
   ],
   "source": [
    "# from each node in the path, calculate its distance to alternative points\n",
    "def sum_path_length(path_idx, X):\n",
    "    path_len_total = 0\n",
    "    if len(path_idx)> 2:\n",
    "        for i in range(len(path_idx)-2):\n",
    "            diff = np.linalg.norm(X.iloc[path_idx[i]] - X.iloc[path_idx[i+1]], ord=2)\n",
    "            path_len_total += diff\n",
    "    else:\n",
    "        path_len_total = np.linalg.norm(X.iloc[path_idx[0]] - X.iloc[path_idx[1]], ord=2)\n",
    "\n",
    "    return path_len_total\n",
    "\n",
    "\n",
    "def calculate_shared_perc(path_idx, X, predictions, alter_class):\n",
    "    alt_class_len_list = []\n",
    "    for point_idx in path_idx:\n",
    "        _, cf_img_dis = find_closest_cf_instance(point_idx, X, predictions, alter_class)\n",
    "        alt_class_len_list.append(cf_img_dis)\n",
    "    differences = [alt_class_len_list[i + 1] - alt_class_len_list[i] for i in range(len(alt_class_len_list) - 1)]\n",
    "\n",
    "    stop_point_idx = next((i for i, diff in enumerate(differences) if diff > 0), len(path_idx))\n",
    "\n",
    "    if stop_point_idx > 0:\n",
    "        total_path_len = sum_path_length(path_idx, X)\n",
    "        shared_path_len = sum_path_length(path_idx[:stop_point_idx+1], X)\n",
    "        shared_perc = shared_path_len/total_path_len\n",
    "    else:\n",
    "        shared_perc = 0\n",
    "\n",
    "    return shared_perc\n",
    "\n",
    "def calculate_avg_shared_perc(path_idx, X, predictions, alter_classes):\n",
    "    shared_perc_list = []\n",
    "    for alt_class in alter_classes:\n",
    "        result = calculate_shared_perc(path_idx, X, predictions, alt_class)\n",
    "        shared_perc_list.append(result)\n",
    "    return np.mean(shared_perc_list)\n",
    "\n",
    "alter_classes = [2, 3, 4, 5, 6, 7, 8]\n",
    "grsp_shared_perc_list = []\n",
    "for path_idx in tqdm(path_points_list):\n",
    "    shared_perc_one = calculate_avg_shared_perc(path_idx, X, predictions, alter_classes)\n",
    "    grsp_shared_perc_list.append(shared_perc_one)\n",
    "print(\"shared percentage of paths from grsp: {}, std: {}\".format(round(np.mean(grsp_shared_perc_list), 2), round(np.std(grsp_shared_perc_list), 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_distance(v0, v1, penalty_term = 1.1):\n",
    "    diff = np.subtract(v0, v1)\n",
    "    reweight_vector = np.where(diff>=0, 1, -penalty_term)\n",
    "    weighted_diff = np.linalg.norm(diff*reweight_vector)\n",
    "    return weighted_diff\n",
    "\n",
    "def sum_path_weighted_length(path_idx, X):\n",
    "    path_len_total = 0\n",
    "    if len(path_idx)> 2:\n",
    "        for i in range(len(path_idx)-2):\n",
    "            diff = calculate_weighted_distance(X.loc[path_idx[i+1]], X.loc[path_idx[i]])\n",
    "            path_len_total += diff\n",
    "    else:\n",
    "        path_len_total = calculate_weighted_distance(X.loc[path_idx[1]], X.loc[path_idx[0]])\n",
    "\n",
    "    return path_len_total\n",
    "\n",
    "grsp_dist_list = []\n",
    "for path_idx in tqdm(path_points_list):\n",
    "    dist = sum_path_weighted_length(path_idx, X)\n",
    "    grsp_dist_list.append(dist)\n",
    "print(\"average distance of shortest path: {}, std: {} \".format(round(np.mean(grsp_dist_list), 2), round(np.std(grsp_dist_list), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(X, img_idx):\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "    image = np.array(X.iloc[img_idx, :])\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape(28, 28), cmap=plt.cm.gray_r, interpolation=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAHQUlEQVR4nO3dL2hWexzH8XMuIv4JBgWDSZNGYSCiQUGYoGAw2RwMnIJdk0HQKhgFZxxqUtAmIljUqIaBTdOGwwkyxHFuW5EPfp/n3nOf59l9vfInfNObXzmctmmargHgN3+N+gCAcSWQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAsKU67Dof3ACbQ9u2pZ0XJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAwZZRHwDj5ufPn+Xt3NxceTs/P1/efv78ubzdt29fectgvCABAoEECAQSIBBIgEAgAQKBBAgEEiAQSIBAIAECgQQI2qZpusqw60oz+M2vX7/K2/X19fL2w4cP5e3Dhw/L2/v375e3y8vL5e0gjhw5Ut6+ePGivN2+ffsw52w6bduWdl6QAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAgUACBP5qSO/evHlT3r569aq8XVlZKW/37NlT3lY/Q+vT9evXy1ufD/bHCxIgEEiAQCABAoEECAQSIBBIgEAgAQKBBAgEEiAQSIDAp4Zs+Pr1a3n76dOn8nbr1q3l7bVr18rbtbW18vbKlSvl7dLSUnk7iGPHjpW3p06d6uUGBuMFCRAIJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQOBTwwH9+PGjvP348WN5OzU1Ncw5/6rZ2dny9vnz5+XtuXPnytv5+fnydmFhobx98OBBeduXQ4cOlbc7duzo8RKqvCABAoEECAQSIBBIgEAgAQKBBAgEEiAQSIBAIAECgQQI2qZpusqw60ozJtjLly/L20H+KHj69Ony9saNG+XtzZs3y9tx8OTJk/L27NmzPV5C27alnRckQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAgb8asuHEiROjPqFZWloa9QnNrl27ytvbt2+XtydPnhzmHEbICxIgEEiAQCABAoEECAQSIBBIgEAgAQKBBAgEEiAQSIDAp4b07v379+Xt48ePe7ykZmZmprydm5vr8RJGzQsSIBBIgEAgAQKBBAgEEiAQSIBAIAECgQQIBBIgEEiAwKeGDOX79+/l7a1bt8rb5eXlYc75o927d5e3V69e7eUGJo8XJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFPDRnKs2fPytuFhYVebhjk88HLly+Xt/v37x/mHDYhL0iAQCABAoEECAQSIBBIgEAgAQKBBAgEEiAQSIBAIAGCtmmarjLsutKMCba4uFjeHj16tLxdWVkZ5pw/OnPmTHn79OnTXm5gMrVtW9p5QQIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRD4qyEb7t69W9729fngIGZmZkZ9ApucFyRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRAIJEAgkACBTw3Z8OXLl1Gf0Fy8eLG8nZ6e7u8QaLwgASKBBAgEEiAQSIBAIAECgQQIBBIgEEiAQCABAoEECHxquMl9+/atvB2HTw0H+VPhzp07e7wEvCABIoEECAQSIBBIgEAgAQKBBAgEEiAQSIBAIAECgQQIfGo4gVZXV8vbCxculLdv374d5pw/mp2dLW+npqZ6uQGG4QUJEAgkQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRA0DZN01WGXVea8R9YXFwsbw8ePNjLDYcPHy5vX79+Xd5u27ZtmHNgIG3blnZekACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgT+ajiB3r17N+oTmuPHj5e3Ph9kUnlBAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEPjUcEysrq6Wt3fu3OnvkKLp6elRnwC984IECAQSIBBIgEAgAQKBBAgEEiAQSIBAIAECgQQIBBIg8KnhmFhfXy9v19bWerlh79695e2BAwd6uQHGiRckQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAQds0TVcZdl1pxn/g3r175e2lS5fK20ePHpW358+fL29h3LRtW9p5QQIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRD41BD43/GpIcA/JJAAgUACBAIJEAgkQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRAIJEAgkACBQAIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgQCCRC0TdN0oz4CYBx5QQIEAgkQCCRAIJAAgUACBAIJEAgkQCCQAIFAAgR/AyCdyFX+GCJQAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_digit(X, 3510)\n",
    "# plot_digit(X, 720)\n",
    "for id in [8725, 4149, 5749, 691]:\n",
    "    plot_digit(X, id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facelift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
