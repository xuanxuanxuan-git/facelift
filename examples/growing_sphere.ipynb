{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With image data, only few methods work -- FACE, GS, prototype\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neural_network import MLPClassifier as NN\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Find the closest instance (using growing sphere) or any final solution\n",
    "# Step 2: compute the pixel difference r\n",
    "# Step 3: binary space partition, and then sort the indices by their distances to the cf instance\n",
    "\n",
    "def calculate_dist(instance_1, instance_2, norm=2):\n",
    "    dist = np.linalg.norm((instance_1 - instance_2), ord=norm)\n",
    "    return dist\n",
    "\n",
    "def find_closest_cf_instance(factual_point_idx, dataset, predictions, cf_class):\n",
    "    min_dist = 785\n",
    "    closest_id = None\n",
    "    factual_point = np.array(dataset.loc[factual_point_idx])\n",
    "    for it_count, (idx, instance) in enumerate(dataset.iterrows()):\n",
    "        prediction = np.argmax(predictions[it_count])\n",
    "        prediction_prob = np.max(predictions[it_count])\n",
    "        if prediction == cf_class and prediction_prob>0.8:\n",
    "            dist = calculate_dist(factual_point, np.array(instance))\n",
    "            # print(idx, dist)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_id = idx\n",
    "    \n",
    "    assert closest_id != None, (\"No counterfactual found\")\n",
    "    return closest_id, min_dist\n",
    "\n",
    "def find_closest_instance(anchor_point, dataset):\n",
    "    min_dist = 785\n",
    "    closest_id = None\n",
    "    for idx, instance in dataset.iterrows():\n",
    "        dist = calculate_dist(anchor_point, instance)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest_id = idx\n",
    "        \n",
    "    assert closest_id != None, (\"No factual point found, try increasing epsilon.\")\n",
    "    return closest_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_point(data, start_point_idx, cf_point_idx, epsilon):\n",
    "    start_point = np.array(data.loc[start_point_idx])\n",
    "    cf_point = np.array(data.loc[cf_point_idx])\n",
    "\n",
    "    distances = pairwise_distances(data.values, [start_point, cf_point], metric=\"l2\")\n",
    "    \n",
    "    ball_indices = np.where((distances[:,0] <= epsilon) & (distances[:, 1] <= epsilon))[0]\n",
    "    ball_indices = list(ball_indices)\n",
    "    if start_point_idx in ball_indices:\n",
    "        ball_indices.remove(start_point_idx)\n",
    "    if cf_point_idx in ball_indices:\n",
    "        ball_indices.remove(cf_point_idx)\n",
    "    return ball_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 10000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "image_size = 28\n",
    "no_of_different_labels = 10\n",
    "image_pixels = image_size * image_size\n",
    "data_path = \"../data/raw_data/mnist/mnist_train.csv\"\n",
    "\n",
    "train_data = pd.read_csv(data_path, \n",
    "                        delimiter=\",\", header=None, dtype=np.uint8)\n",
    "train_imgs = train_data.iloc[:, 1:]/255   # divide by 255 only for model prediction\n",
    "train_imgs = train_imgs.astype(\"float32\")\n",
    "# train_imgs = train_data.iloc[:, 1:]\n",
    "train_labels = np.asarray(train_data.iloc[:, :1][0])\n",
    "\n",
    "# subsample the original dataset, each digit has 1000 instances rather than 5000-6000\n",
    "all_indices = []\n",
    "for digit in np.arange(0,10):\n",
    "    single_digit_indices = set(np.where(train_labels == digit)[0][:1000])\n",
    "    all_indices = set(all_indices).union(single_digit_indices)\n",
    "print(\"Number of instances:\", len(all_indices))\n",
    "\n",
    "X = train_imgs.iloc[list(all_indices), :]\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "y = train_labels[list(all_indices)]\n",
    "\n",
    "clf = NN(max_iter=5000).fit(X, y)\n",
    "predictions = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of counterfactual instance: 3510\n",
      "Distance: 6.379251\n",
      "[23, 77, 78, 113, 177, 201, 205, 315, 345, 351, 355, 357, 397, 443, 447, 455, 475, 492, 507, 508, 553, 573, 593, 609, 611, 671, 691, 698, 711, 747, 765, 779, 783, 809, 833, 835, 871, 891, 905, 919, 959, 1051, 1085, 1115, 1181, 1211, 1331, 1405, 1425, 1445, 1497, 1527, 1579, 1597, 1601, 1909, 1915, 2039, 2045, 2047, 2166, 2335, 2355, 2393, 2429, 2495, 2497, 2505, 2563, 2583, 2645, 2667, 2695, 2717, 2719, 2807, 2823, 2831, 2843, 2853, 2907, 3331, 3373, 3411, 3427, 3487, 3549, 3561, 3567, 3605, 3729, 3733, 3797, 3831, 3851, 3885, 3889, 3897, 3955, 3956, 4029, 4069, 4105, 4109, 4129, 4137, 4149, 4193, 4225, 4237, 4267, 4351, 4405, 4445, 4553, 4561, 4569, 4623, 4685, 4933, 5051, 5073, 5075, 5107, 5149, 5189, 5221, 5225, 5235, 5237, 5245, 5271, 5301, 5375, 5395, 5425, 5428, 5429, 5439, 5443, 5477, 5483, 5527, 5543, 5571, 5601, 5635, 5643, 5655, 5667, 5675, 5681, 5713, 5731, 5749, 5785, 5859, 5903, 5915, 5933, 5957, 6075, 6083, 6135, 6165, 6183, 6229, 6247, 6303, 6356, 6365, 6371, 6411, 6413, 6423, 6499, 6531, 6613, 6877, 6925, 6985, 7007, 7057, 7119, 7188, 7421, 7435, 7454, 7533, 7729, 7837, 7857, 7951, 7971, 7993, 8053, 8063, 8083, 8087, 8095, 8112, 8203, 8255, 8258, 8291, 8319, 8331, 8373, 8379, 8383, 8388, 8423, 8512, 8589, 8625, 8679, 8705, 8725]\n"
     ]
    }
   ],
   "source": [
    "factual_img_idx = 3 # digit 1\n",
    "cf_class = 9\n",
    "\n",
    "cf_img_idx, cf_img_dis = find_closest_cf_instance(factual_img_idx, X, predictions, cf_class)\n",
    "print(\"Index of counterfactual instance:\", cf_img_idx)\n",
    "print(\"Distance:\", cf_img_dis)\n",
    "\n",
    "all_path_points = find_point(X, factual_img_idx, cf_img_idx, cf_img_dis)\n",
    "print(all_path_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3510\n",
      "[3, 8725, 4149, 5749, 691, 3510]\n"
     ]
    }
   ],
   "source": [
    "# BSP Algorithm\n",
    "def bsp_partition(data, indices, point1, point2, threshold):\n",
    "    distances = pairwise_distances(data[indices], [point1, point2], metric='l2')\n",
    "    partition = np.where((distances[:,0] <= threshold) & (distances[:, 1] <= threshold))[0]\n",
    "    return indices[partition]\n",
    "\n",
    "# Recursive BSP function\n",
    "def recursive_bsp(data, indices, point1, point2, threshold, min_threshold):\n",
    "\n",
    "    if threshold < min_threshold:\n",
    "        np.random.seed(42)\n",
    "        result = np.random.choice(indices, size=1)\n",
    "        return result\n",
    "    \n",
    "    midpoint = (point1 + point2) / 2.0\n",
    "    threshold = threshold-1\n",
    "    partition1 = bsp_partition(data, indices, point1, midpoint, threshold)\n",
    "    partition2 = bsp_partition(data, indices, midpoint, point2, threshold)\n",
    "    \n",
    "    if len(partition1) + len(partition2) == 0:\n",
    "        np.random.seed(42)\n",
    "        result = np.random.choice(indices, size=1)\n",
    "        return result\n",
    "    else:\n",
    "        if len(partition1) != 0:\n",
    "            indices1 = recursive_bsp(data, partition1, point1, midpoint, threshold, min_threshold)\n",
    "        else:   # in this case, partition2 is not empty\n",
    "            indices1 = []\n",
    "        \n",
    "        if len(partition2) != 0:\n",
    "            indices2 = recursive_bsp(data, partition2, midpoint, point2, threshold, min_threshold)\n",
    "        else:\n",
    "            indices2 = []\n",
    "\n",
    "    return np.concatenate((indices1, indices2))\n",
    "\n",
    "def sort_path_points(X_np, selected_indices, cf_img):\n",
    "    cf_point = np.array(cf_img).reshape(1, -1)\n",
    "\n",
    "    distances = pairwise_distances(X_np[selected_indices], cf_point, metric=\"l2\")\n",
    "    distances = np.squeeze(distances)\n",
    "    sorted_indices = np.array(selected_indices)[np.argsort(distances)][::-1]\n",
    "\n",
    "    return list(sorted_indices)\n",
    "\n",
    "def ground_vector_path(X_np, factual_img_idx, cf_img_idx, cf_img_dis, all_indices, min_threshold):\n",
    "    if not all_indices:\n",
    "        return []\n",
    "    \n",
    "    point1 = X_np[factual_img_idx]\n",
    "    point2 = X_np[cf_img_idx]\n",
    "    initial_threshold = cf_img_dis\n",
    "\n",
    "    min_threshold = min_threshold\n",
    "    all_indices = np.array(all_indices)\n",
    "\n",
    "    selected_indices = recursive_bsp(X_np, all_indices, point1, point2, initial_threshold, min_threshold)\n",
    "    selected_indices = list(map(int, set(selected_indices)))\n",
    "    # print(selected_indices)\n",
    "    sorted_indices = sort_path_points(X_np, selected_indices, point2)\n",
    "    sorted_indices.append(cf_img_idx)\n",
    "    sorted_indices.insert(0, factual_img_idx)\n",
    "    return sorted_indices\n",
    "\n",
    "\n",
    "print(factual_img_idx)\n",
    "print(cf_img_idx)\n",
    "X_np = X.to_numpy()\n",
    "selected_path_points = ground_vector_path(X_np, factual_img_idx, cf_img_idx, cf_img_dis, all_indices=all_path_points, min_threshold=2)\n",
    "print(selected_path_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 8725, 4149, 5749, 691, 3510], [6, 8660, 6052, 5256, 8382, 7922], [8, 2616, 3900, 7588, 3662], [14, 7650, 8032, 3662], [23, 201, 4105, 611, 7233], [24, 5174, 9717], [40, 7060, 3714, 3662], [59, 3729, 2583, 1579, 691, 3510], [67, 7472, 4708, 2198, 7176, 5390], [70, 7898, 8732, 48], [72, 1942, 3662], [77, 5601, 5395, 3956, 691, 3510], [78, 7533, 7119, 691, 3510], [99, 1081, 1463, 7365], [102, 7020, 6748, 7138, 7588, 3662], [104, 3272, 5336, 8382, 7922], [105, 6613, 1181, 6499, 3956, 3510], [112, 3926, 5530, 3662], [113, 3956, 3510], [124, 7603, 7176, 5390], [128, 3478, 3394, 5708, 7393, 8574, 3662], [134, 3070, 9508], [152, 6775, 4166, 4070, 8602, 3714, 3662], [174, 2906, 8106, 3662], [177, 6247, 1445, 5691, 3355], [184, 5814, 6586, 7588, 3662], [200, 4467, 6116, 746, 2600], [201, 5749, 691, 3510], [205, 779, 8679, 3956, 3510], [208, 6208, 4913, 251, 3703, 3355], [211, 6208, 4913, 5691, 3355], [224, 9214, 8217, 6459], [231, 2894, 2154, 4166, 8602, 5390], [248, 1696, 5256, 6702, 7922], [251, 6395, 5691, 3355], [269, 4953, 4286, 3345, 3755, 7973, 5114, 5691, 3355], [270, 6384, 4998, 6793, 8602, 5390], [276, 8106, 2198, 3662], [290, 1658, 2870, 3878, 7469, 5390], [309, 3971, 2957, 3295, 7472, 5428, 1521, 7365], [310, 3714, 8032, 3662], [315, 7533, 5571, 8589, 691, 3510], [345, 315, 5075, 5571, 691, 3510], [351, 8589, 3510], [355, 5075, 8083, 3956, 691, 3510], [357, 7971, 3510], [358, 7572, 6926, 2616, 4790, 7650, 7588, 3662], [366, 72, 4484, 3662], [382, 1450, 4731, 6116, 4813, 7074, 2600], [394, 8040, 7850, 5020, 8176, 5898], [397, 5543, 891, 3956, 3510], [398, 5058, 484, 4484, 3662], [406, 248, 6052, 5256, 4942, 7922], [408, 4186, 4772, 8106, 8032, 3662], [416, 6247, 6395, 3355], [443, 5675, 891, 5731, 691, 3510], [447, 871, 397, 5107, 3956, 3510], [450, 6408, 7324, 4772, 7060, 3714, 4484, 3662], [454, 4064, 3120, 4484, 3662], [455, 5601, 5643, 691, 3510], [466, 7912, 6122, 5390], [470, 2830, 5898], [475, 3549, 7233], [484, 5882, 6244, 4484, 3662], [491, 7747, 3545, 3798, 7233], [492, 6371, 5527, 691, 3510], [507, 5749, 1497, 3510], [508, 4105, 5189, 3549, 8185, 7233], [510, 2692, 1807, 3763, 7609, 6380, 5898], [533, 491, 5305, 3545, 8185, 7233], [535, 7747, 8351, 3798, 7233], [538, 1065, 7609, 7491, 7317, 1031, 7365], [552, 4476, 6647, 2906, 8574, 3662], [553, 1085, 3733, 691, 3510], [556, 8156, 8166, 3412, 3662], [572, 8538, 5610, 7060, 3714, 3662], [573, 5749, 3510], [587, 7747, 3509, 8185, 7233], [593, 8291, 7303, 475, 8185, 7233], [604, 8402, 3662], [609, 4149, 5749, 691, 3510], [618, 3306, 5058, 3900, 3662], [637, 7831, 1155, 2811, 3103, 6736, 7303, 8185, 611, 7233], [638, 5864, 2716, 3900, 3120, 3662], [648, 8738, 5114, 4166, 8402, 7176, 5390], [671, 691, 3510], [676, 7324, 7469, 3926, 276, 3662], [678, 4492, 7060, 7588, 3662], [], [698, 2393, 6499, 8053, 3956, 3510], [710, 8348, 4766, 7838, 2906, 3662], [711, 6423, 1915, 691, 3510], [738, 5336, 4696, 7922], [747, 5221, 5149, 905, 691, 3510], [765, 8083, 8053, 3956, 691, 3510], [779, 891, 1915, 8679, 691, 3510], [780, 7572, 2616, 7588, 3662], [783, 205, 891, 3956, 1497, 3510], [809, 833, 8373, 5395, 3956, 3510], [821, 6463, 8331, 7421, 8087, 959, 3510]]\n",
      "average path length: 5.21, std: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_points_list = []\n",
    "X_np = X.to_numpy()\n",
    "top_100_one_indices = list(np.where(y==1)[0])[:100]\n",
    "\n",
    "for idx in tqdm(top_100_one_indices):\n",
    "    \n",
    "    factual_img_idx = idx\n",
    "    cf_img_idx, cf_img_dis = find_closest_cf_instance(factual_img_idx, X, predictions, cf_class)\n",
    "    # print(factual_img_idx, cf_img_idx)\n",
    "    all_path_points = find_point(X, factual_img_idx, cf_img_idx, cf_img_dis)\n",
    "    selected_path_points = ground_vector_path(X_np, factual_img_idx, cf_img_idx, cf_img_dis, all_path_points, min_threshold=2)\n",
    "    path_points_list.append(selected_path_points)\n",
    "print(path_points_list)\n",
    "path_len = [len(path) for path in path_points_list]\n",
    "print(\"average path length: {}, std: {}\".format(round(np.average(path_len), 2), round(np.std(path_len), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average path length: 5.64, std: 1.8\n"
     ]
    }
   ],
   "source": [
    "path_len_proto = [len(path) for path in proto_path_points_list]\n",
    "print(\"average path length: {}, std: {}\".format(round(np.average(path_len_proto), 2), round(np.std(path_len_proto), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [04:54<00:00, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared percentage of paths from grsp: 0.53, std: 0.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from each node in the path, calculate its distance to alternative points\n",
    "def sum_path_length(path_idx, X):\n",
    "    path_len_total = 0\n",
    "    if len(path_idx)> 2:\n",
    "        for i in range(len(path_idx)-2):\n",
    "            diff = np.linalg.norm(X.iloc[path_idx[i]] - X.iloc[path_idx[i+1]], ord=2)\n",
    "            path_len_total += diff\n",
    "    else:\n",
    "        path_len_total = np.linalg.norm(X.iloc[path_idx[0]] - X.iloc[path_idx[1]], ord=2)\n",
    "\n",
    "    return path_len_total\n",
    "\n",
    "\n",
    "def find_close_cf_instances(factual_point_idx, dataset, predictions, cf_class):\n",
    "    min_dist = 785\n",
    "    all_dist = []\n",
    "    factual_point = np.array(dataset.loc[factual_point_idx])\n",
    "    for it_count, (idx, instance) in enumerate(dataset.iterrows()):\n",
    "        prediction = np.argmax(predictions[it_count])\n",
    "        prediction_prob = np.max(predictions[it_count])\n",
    "        if prediction == cf_class and prediction_prob>0.8:\n",
    "            dist = calculate_dist(factual_point, np.array(instance))\n",
    "            all_dist.append(dist)\n",
    "    \n",
    "    close_indices = np.argsort(all_dist)[2:26:5]\n",
    "    close_dist = sorted(all_dist)[2:26:5]\n",
    "\n",
    "    return close_indices, close_dist\n",
    "\n",
    "\n",
    "def calculate_shared_perc(path_idx, X, predictions, alter_class, count):\n",
    "    alt_class_len_list = []\n",
    "    for point_idx in path_idx:\n",
    "        _, cf_img_dis = find_close_cf_instances(point_idx, X, predictions, alter_class)\n",
    "        cf_img_dis = cf_img_dis[count]\n",
    "        alt_class_len_list.append(cf_img_dis)\n",
    "    differences = [alt_class_len_list[i + 1] - alt_class_len_list[i] for i in range(len(alt_class_len_list) - 1)]\n",
    "\n",
    "    stop_point_idx = next((i for i, diff in enumerate(differences) if diff > 0), len(path_idx))\n",
    "\n",
    "    if stop_point_idx > 0:\n",
    "        total_path_len = sum_path_length(path_idx, X)\n",
    "        shared_path_len = sum_path_length(path_idx[:stop_point_idx+1], X)\n",
    "        shared_perc = shared_path_len/total_path_len\n",
    "    else:\n",
    "        shared_perc = 0\n",
    "\n",
    "    return shared_perc\n",
    "\n",
    "def calculate_avg_shared_perc(path_idx, X, predictions, alter_classes):\n",
    "    shared_perc_list = []\n",
    "    for count, alt_class in enumerate(alter_classes):\n",
    "        result = calculate_shared_perc(path_idx, X, predictions, alt_class, count)\n",
    "        shared_perc_list.append(result)\n",
    "    return np.mean(shared_perc_list)\n",
    "\n",
    "alter_classes = [9, 9, 9, 9, 9]\n",
    "grsp_shared_perc_list = []\n",
    "# for path_idx in tqdm(path_points_list):\n",
    "for path_idx in tqdm(proto_path_points_list):\n",
    "    shared_perc_one = calculate_avg_shared_perc(path_idx, X, predictions, alter_classes)\n",
    "    grsp_shared_perc_list.append(shared_perc_one)\n",
    "print(\"shared percentage of paths from grsp: {}, std: {}\".format(round(np.mean(grsp_shared_perc_list), 2), round(np.std(grsp_shared_perc_list), 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 731.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average distance of shortest path: 71.66, std: 34.11 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_weighted_distance(v0, v1, penalty_term = 1.1):\n",
    "    diff = np.subtract(v0, v1)\n",
    "    reweight_vector = np.where(diff>=0, 1, -penalty_term)\n",
    "    weighted_diff = np.linalg.norm(diff*reweight_vector, ord=1)\n",
    "    return weighted_diff\n",
    "\n",
    "def sum_path_weighted_length(path_idx, X):\n",
    "    path_len_total = 0\n",
    "    if len(path_idx)> 2:\n",
    "        for i in range(len(path_idx)-2):\n",
    "            diff = calculate_weighted_distance(X.loc[path_idx[i+1]], X.loc[path_idx[i]])\n",
    "            path_len_total += diff\n",
    "    else:\n",
    "        path_len_total = calculate_weighted_distance(X.loc[path_idx[1]], X.loc[path_idx[0]])\n",
    "\n",
    "    return path_len_total\n",
    "\n",
    "grsp_dist_list = []\n",
    "for path_idx in tqdm(path_points_list):\n",
    "    if len(path_idx)==0:\n",
    "        continue\n",
    "    dist = sum_path_weighted_length(path_idx, X)\n",
    "    grsp_dist_list.append(dist)\n",
    "print(\"average distance of shortest path: {}, std: {} \".format(round(np.mean(grsp_dist_list), 2), round(np.std(grsp_dist_list), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_shared_perc_proto(path_idx, X, alt_cf_point):\n",
    "    alt_point_len_list = []\n",
    "    for point_idx in path_idx:\n",
    "        dist = np.linalg.norm(X.loc[point_idx] - X.loc[alt_cf_point], ord=2)\n",
    "        alt_point_len_list.append(dist)\n",
    "    differences = [alt_point_len_list[i + 1] - alt_point_len_list[i] for i in range(len(alt_point_len_list) - 1)]\n",
    "    stop_point_idx = next((i for i, diff in enumerate(differences) if diff > 0), len(path_idx))\n",
    "    \n",
    "    if stop_point_idx > 0:\n",
    "        total_path_len = sum_path_length(path_idx, X)\n",
    "        shared_path_len = sum_path_length(path_idx[:stop_point_idx+1], X)\n",
    "        shared_perc = shared_path_len/total_path_len\n",
    "    else:\n",
    "        shared_perc = 0\n",
    "\n",
    "    return shared_perc\n",
    "\n",
    "def calculate_avg_shared_perc_proto(path_idx, X, all_solution_idx):\n",
    "    shared_perc_list = []\n",
    "    for idx in all_solution_idx[1:-1]:\n",
    "        shared_perc = calculate_shared_perc_proto(path_idx, X, idx)\n",
    "        shared_perc_list.append(shared_perc)\n",
    "    return np.mean(shared_perc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load solution\n",
    "with open(\"proto_solutions.pickle\", \"rb\") as inter_data_file:\n",
    "    proto_solution_idx = pickle.load(inter_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(proto_solution_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared percentage of paths from proto: 0.2, std: 0.14\n"
     ]
    }
   ],
   "source": [
    "proto_path_points_list = []\n",
    "proto_shared_perc_list = []\n",
    "for one_solution_idx in proto_solution_idx:\n",
    "    path_points_list = []\n",
    "\n",
    "    factual_img_idx = one_solution_idx[0]\n",
    "    cf_img_idx = one_solution_idx[-1]\n",
    "    cf_img_dis = np.linalg.norm(X.loc[factual_img_idx]-X.loc[cf_img_idx],ord=2)\n",
    "\n",
    "    all_path_points = find_point(X, factual_img_idx, cf_img_idx, cf_img_dis)\n",
    "    selected_path_points = ground_vector_path(X_np, factual_img_idx, cf_img_idx, cf_img_dis, all_path_points, min_threshold=2)\n",
    "    proto_path_points_list.append(selected_path_points)\n",
    "    shared_perc = calculate_avg_shared_perc_proto(selected_path_points, X, one_solution_idx)\n",
    "    proto_shared_perc_list.append(shared_perc)\n",
    "\n",
    "print(\"shared percentage of paths from proto: {}, std: {}\".format(round(np.mean(proto_shared_perc_list), 2), round(np.std(proto_shared_perc_list), 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 541.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average distance of shortest path: 91.95, std: 47.92 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "proto_dist_list = []\n",
    "for path_idx in tqdm(proto_path_points_list):\n",
    "    if len(path_idx)==0:\n",
    "        continue\n",
    "    dist = sum_path_weighted_length(path_idx, X)\n",
    "    proto_dist_list.append(dist)\n",
    "print(\"average distance of shortest path: {}, std: {} \".format(round(np.mean(proto_dist_list), 2), round(np.std(proto_dist_list), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(X, img_idx):\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "    image = np.array(X.iloc[img_idx, :])\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape(28, 28), cmap=plt.cm.gray_r, interpolation=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFICAYAAAAyFGczAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAGGElEQVR4nO3dr6oVWByG4b2HARGLQdFo8RoEi1kRxOoFmDRYtImK2SAniMF4sHgLFpNNEPyHoNFgkHMB7kmm4WV+6mzO2e7nyV9Y6WWVxVouFovVAoB/+Wu/DwBwUAkkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiD8PR2uVh7cAH+G5XI52rlBAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkAChL/3+wAcHN+/fx9v7927N97evXv3V47znx48eDDe3rhxYy1n4M/mBgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSICwXi8VqMlytRjM22P3798fb27dvr/EkM5cvXx5vnz17tsaTsGmWy+Vo5wYJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiD41fAP9+HDh/H2yZMnazzJ/+/169fj7ZcvX8bbkydP/spx+AO5QQIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECJ4abqCfeT54/vz58fbz58/j7enTp8fbS5cujbcPHz4cbz9+/Djefv36dbz11JAf3CABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgRPDQ+I9+/fj7cXLlwYbz99+jTenjhxYry9fv36eHvt2rXx9sWLF+Pty5cvx9u9vb3xFn5wgwQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEDw1XKOf+UlvXc8HDx06NN4+ffp0vD137tx4exDs7OyMt2fPnl3jSdgkbpAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYKnhmt0+PDh8fbMmTPj7alTp8bbW7dujbeb9nwQ1s0NEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRA8NRwjY4cOTLe7u7urvEkwK9wgwQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIDgV0O2wpUrV/b7CGwgN0iAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIfjVkK+zu7o63Fy9eXONJ2CRukABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRD8ashWuHr16n4fgQ3kBgkQBBIgCCRAEEiAIJAAQSABgkACBIEECAIJEAQSIHhqyFY4duzYfh+BDeQGCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgeGrIVtjZ2RlvHz16tMaTsEncIAGCQAIEgQQIAgkQBBIgCCRAEEiAIJAAQSABgkACBE8N2Qp7e3v7fQQ2kBskQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIDgqSFb4d27d+Ptt2/fxtujR4/+/GHYGG6QAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCp4ZshVevXo23N2/eHG8fP378C6dhU7hBAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIy8VisZoMV6vRDH7L27dvx9s7d+6Mt2/evBlvnz9/Pt4eP358vOXgWC6Xo50bJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiA4KkhsHU8NQT4TQIJEAQSIAgkQBBIgCCQAEEgAYJAAgSBBAgCCRAEEiAIJEAQSIAgkABBIAGCQAIEgQQIAgkQBBIgCCRAEEiAMP7VEGDbuEECBIEECAIJEAQSIAgkQBBIgCCQAEEgAYJAAoR/AICrfC80S2nAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_digit(X, 3510)\n",
    "# plot_digit(X, 720)\n",
    "for id in [6, 5304, 1696, 6702, 212, 7478]:\n",
    "    plot_digit(X, id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facelift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
